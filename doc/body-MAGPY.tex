\section{Introduction}


\section{Basic Concept}

The program is loosely related to the ObsPy package. Some functions are (almost) identically taken from this package. Among them are the read functions and the spectrogram.

\subsection{DI measurements}

\subsection{Variometer and Scalar measurements}

\subsection{The Programs Layout}


\section{Input and Output Formats}

\subsection{Supported input types}

Any data loaded into the MagPy analysis software is transferred into an internal data structure. This structure represents a time series with a number of keywords which represent individual columns of the original data. The following keywords (table) are generally available for all input data, although most input data only use a few of them.

KEYLIST = ['time','x','y','z','f','t1','t2','var1','var2','var3','var4','var5','dx','dy','dz','df','str1','str2','str3','str4','flag','comment','typ','sectime']


\subsection{Supported output types}

\subsection{Using databases}


\section{Application}

\subsection{Basic data analysis}

\subsubsection{Reading and Plotting}

Plotting all data from a certain directory:
\begin{verbatim}
    from dev_magpy_stream import *
    st = pmRead(path_or_url=os.path.normpath('datapath\\*'))
    st.pmplot(['x','y','z'])
\end{verbatim}
The first line denotes the import line for the required package. The second line contains the read command which load the selected data into an internal memory. The data will be stored as a structured time series, as stream ``st'', for further treatment. ``datapath'' can either be an absolute path (e.g. c:$\\$data$\\$instrument$\\$*, /data/instrument/*) or a relative path (e.g. ..$\\$data$\\$instrument\\*, ../data/instrument/*). Any function is then performed on the stream ``st'' by using the following structure: st.function(options). For plotting the time series the pmplot function is used. This function requires the

Trimming data with starttime and/or endtime limits. Starttime and endtime formats:
\begin{verbatim}
    st = pmRead(path_or_url=os.path.normpath('datapath\\*'),starttime='2011-7-8',endtime=datetime(2011,7,18,13,0,0,0))
    st.pmplot(['x','y','z'])
\end{verbatim}

\subsubsection{Writing data}

\begin{verbatim}
    from dev_magpy_stream import *
    st = pmRead(...)
    st.DoUsefulThings(options)
    st.pmwrite('outputpath')
\end{verbatim}

\subsubsection{Filtering/Smoothing/Interpolation}

The first example shows how to filter data using gaussian and linear filters.
\begin{verbatim}
    st = pmRead(...)
    st = st.filtered(filter_type='gauss',filter_width=timedelta(minutes=1))
    st.pmplot(['x','y','z'])
    st.filtered(filter_type='linear',filter_width=timedelta(minutes=60),filter_offset=timedelta(minutes=30))
    st.pmplot(['x','y','z'])
\end{verbatim}

Smoothing:
\begin{verbatim}
    st = pmRead(path_or_url=os.path.normpath('datapath\\*'),starttime='2011-7-8',endtime='2011-7-9')
    st = st.smooth(['x'],window_len=21)
    st.pmplot(['x','y','z'])
\end{verbatim}

Approximating functions and fitting:
\begin{verbatim}
    st = pmRead(path_or_url=os.path.normpath('datapath\\*'),starttime='2011-7-8',endtime='2011-7-9')
    func = st.fit(['f'],fitfunc='spline',knotstep=0.05)
    st.pmplot(['f'],function=func)
\end{verbatim}

\begin{verbatim}
    st = pmRead(path_or_url=os.path.normpath('datapath\\*'),starttime='2011-7-8',endtime='2011-7-9')
    func = st.interpol(['x','y','z'])
    st.pmplot(['f'],function=func)
\end{verbatim}

\subsubsection{Removing spikes}

Outlier detection is based on quartiles. Calculated is the interquartile range ($IQR$, which is the difference between the first and third quartile ($Q3 - Q1$). The interquartile range is termed to be a relatively robust statistic compared to the range and standard deviation. $Q1$ is based on the lower 25\% of data, $Q3$ on the upper part, after using medians to divide the data set. Using an optional threshold value outliers are then characterized by exceeding the limit defined by
\begin{equation}\label{outlier}
    L = M \pm t*IQR
\end{equation}
where $L$ denotes the limit, $M$ is the median of the values and $t$ is the optional threshold value. By default the threshold value is set to 4, which keeps all data except prominent spikes even during stormy conditions in a noisy environment. The outlier function accepts four optional keywords for modifying threshold, time window, and the column key. Shown below are the default values:
\begin{verbatim}
stream = stream.routlier(keys=['f'], timerange=timedelta(hours=1), threshold = 4.0)
\end{verbatim}
Outlying data is \emph{not} removed from the data set but flagged (see next section). The log file (see section \ref{logging}) contains a list of all flagged data points.

\subsubsection{Flagging data}\label{flagging}

\begin{verbatim}
st = pmRead(path_or_url=os.path.normpath('datapath\\*'),starttime='2011-7-8',endtime='2011-7-9')
st = st.routlier()
st = st.flag_stream('f',3,"Moaing",datetime(2010,7,18,12,0,0,0),datetime(2010,7,18,13,0,0,0))
st = st.remove_flagged()
st.pmplot(['f'],function=func)
st = st.get_gaps(gapvariable=True)
st.pmplot(['f','var2'])
\end{verbatim}


\subsection{DI and Baselines}

\subsubsection{DI analysis}

\subsubsubsection{Calculating absolutes}

\begin{verbatim}
abso = analyzeAbsFiles(path_or_url=source, alpha=3.25, beta=0.0, variopath=os.path.normpath('..\\dat\\lemi025\\*'), scalarpath=os.path.normpath('..\\dat\\didd\\*'), archivepath=os.path.normpath('..\\dat\\absolutes\\analyzed'))
abso.pmwrite('..\\dat\\output\\absolutes\\',coverage='all',mode='replace',filenamebegins='absolutes_lemi')
func = abso.fit(['dx','dy','dz'],fitfunc='spline',knotstep=0.05)
abso.pmplot(['dx','dy','dz'],function=func, plottitle = "Ex 12 - Analysis of absolute values and spline fit")
\end{verbatim}
The analyzeAbsFiles function reads DI files located in directory source (e.g. os.path.normpath('..\\dat\\absolutes\\raw')). For calculation, the variometer data in variopath is used and if no scalar values are provided along with the DI file, scalar data from scalarpath is used. If the analysis is successful, DI files are moved to the archive directory. Alpha and beta describe the rotation angles. Alpha is the horizontal angle. In case of an HDZ oriented instrument, alpha corresponds to D at the time of instrument orientation. Beta describes deviations from horizontal configurations and is usually zero in case of suspended systems.

The analyzeAbsFiles function is located in the absolutes package and reads special DI file formats. The output of the function is a stream class of the stream package, and thus can be treated/visualized using any basic stream analysis routine as described in table xxx.

For the write command the following options are now used: Coverage$=$all saves all data to one file and does not include any date in the filename. This requires option filenamebegins to be set, which determines the actual file name. Mode$=$replace indicates that any already existing input in an existing summary file at the same save-location will be replaced by new analyzes. All others remain untouched.

\subsubsubsection{Metadata and collimation angles}



\subsubsection{Baseline calculation}
\begin{verbatim}
abslemi = pmRead(path_or_url=os.path.normpath(r'..\\dat\\output\\absolutes\\absolutes_lemi.txt'))
func = abslemi.fit(['dx','dy','dz'],fitfunc='spline',knotstep=0.05)
abslemi.pmplot(['dx','dy','dz'],function=func, plottitle = "Ex 13 - Baseline values and spline fit")
lemi = pmRead(path_or_url=os.path.normpath('..\\dat\\lemi025\\*'),starttime='2011-09-1',endtime='2011-9-30')
lemi = lemi.rotation(alpha=3.3,beta=0.0)
lemi = lemi.baseline(abslemi,knotstep=0.05,plotbaseline=True)
lemi.pmplot(['x','y','z'])
\end{verbatim}

Baseline correction is done by the baseline function. Reading the file containing absolute data corrected with the variometer is done in the first line. The fields dx, dy, and dz contain the baseline values for the specified variometer. As shown above a spline fit can be easily calculated for the absolute components. Then the variometer data is loaded and rotated according to its orientation matrix (HDZ here). The baseline correction is then done using the baseline function.


\subsubsection{Baseline stability}

\subsection{Auxiliary data}


\subsection{Advanced data analysis}

\subsubsection{Merging and Comparing records}

\subsubsection{Spectral analysis}

\subsubsection{Variation anaylsis/Strom recognition}

\begin{verbatim}
    st = pmRead(...)
    func = st.fit(['x','y','z'],fitfunc='spline',knotstep=0.1)
    st = st.aic_calc('x',timerange=timedelta(hours=1))
    st.pmplot(['x','y','z','var2'],function=func)
    fmi = st.k_fmi(fitdegree=2)
    fmi = st.k_fmi(fitfunc='spline',knotstep=0.4)
    col = st._get_column('var2')
    st = st._put_column(col,'y')
    st = st.differentiate()
    st.pmplot(['x','var2','dy','t2'],symbollist = ['-','-','-','z'])
\end{verbatim}


\subsection{Automizing analysis procedures}

\subsubsection{Scripting}

\subsubsection{Logging and Notification}\label{logging}

use the python logging package

\subsection{Summary of supported routines}

Show table containing all functions, their purpose and the available keys.

\section{Advanced}

\subsection{Creating import/export filters}

\subsection{Adding Analysis Functions}

\section{Discussion}

